[
{
	"uri": "//localhost:1313/",
	"title": "Create a Serverless Chatbot Using Amazon Bedrock, Amazon Kendra, and Your Own Data",
	"tags": [],
	"description": "",
	"content": "Create a Serverless Chatbot Using Amazon Bedrock, Amazon Kendra, and Your Own Data Overall In this workshop, you will embark on a comprehensive journey to create a serverless chatbot using cutting-edge generative AI technologies. You\u0026rsquo;ll leverage Amazon Bedrock, Amazon Kendra, and your own data to build an intelligent conversational interface that can retrieve and generate contextually relevant responses. The workshop will guide you through configuring multiple services including AWS Lambda, API Gateway, and AWS Amplify, and you\u0026rsquo;ll work with various large language models like Claude 3, Mistral, and Llama. By the end of the workshop, you\u0026rsquo;ll have a fully functional chatbot that can interact with enterprise knowledge bases using Retrieval-Augmented Generation (RAG) techniques. This workshop addresses real-world use cases where organizations need intelligent, data-driven conversational interfaces.\nYou\u0026rsquo;ll learn how to solve challenges such as enterprise knowledge discovery, customer support automation, and information retrieval across complex document repositories. The solution you\u0026rsquo;ll build can be applied in numerous business scenarios, including technical support systems, HR knowledge management, compliance document querying, and research information synthesis. By mastering these techniques, you\u0026rsquo;ll be equipped to create AI-powered solutions that can transform how businesses interact with their data, providing faster, more accurate, and context-aware responses to complex queries.\nYou will create the following architecture for this workshop:\nContent Introduction Preparation Connect to EC2 instance Manage session logs Port Forwarding Clean up resources "
},
{
	"uri": "//localhost:1313/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Overall In this workshop, you will embark on a comprehensive journey to create a serverless chatbot using cutting-edge generative AI technologies. You\u0026rsquo;ll leverage Amazon Bedrock, Amazon Kendra, and your own data to build an intelligent conversational interface that can retrieve and generate contextually relevant responses. The workshop will guide you through configuring multiple services including AWS Lambda, API Gateway, and AWS Amplify, and you\u0026rsquo;ll work with various large language models like Claude 3, Mistral, and Llama. By the end of the workshop, you\u0026rsquo;ll have a fully functional chatbot that can interact with enterprise knowledge bases using Retrieval-Augmented Generation (RAG) techniques. This workshop addresses real-world use cases where organizations need intelligent, data-driven conversational interfaces.\nYou\u0026rsquo;ll learn how to solve challenges such as enterprise knowledge discovery, customer support automation, and information retrieval across complex document repositories. The solution you\u0026rsquo;ll build can be applied in numerous business scenarios, including technical support systems, HR knowledge management, compliance document querying, and research information synthesis. By mastering these techniques, you\u0026rsquo;ll be equipped to create AI-powered solutions that can transform how businesses interact with their data, providing faster, more accurate, and context-aware responses to complex queries.\nYou will create the following architecture for this workshop:\nüß© Components Users: End-users of the chatbot Web UI: User interface for chatbot interaction AWS Amplify (React, Vue.js): Manages front-end and authentication, specifically using React or Vue.js Amazon API Gateway: Handles API requests AWS Lambda (RAG/KB/LLM Functions): Executes serverless functions for Retrieval-Augmented Generation, Knowledge Base operations, and LLM interactions Amazon Bedrock: Provides access to AI models and services Large Language Models (Claude 3, Mistral, Llama etc.): AI models powering responses Knowledge Bases: Stores structured information Amazon S3: Object storage for documents and data Documents (PDF, CSV, TXT etc.): Various file types for ingestion Amazon Kendra: Intelligent search service Amazon OpenSearch: Vector database and search engine for efficient similarity search Amazon Cognito: User authentication and authorization üîÑ Workflow Users interact with the Web UI Requests routed through API Gateway to Lambda functions Lambda functions use Bedrock for LLM access, RAG operations, and Knowledge Base interactions Knowledge retrieved from Knowledge Bases, S3, Kendra, or OpenSearch System incorporates various document types to enhance the knowledge base ‚ú® Key Features Scalable, serverless architecture Leverages various LLM models including Claude 3, Mistral, and Llama Incorporates enterprise knowledge through Kendra and custom knowledge bases Secure authentication with Cognito Flexible document ingestion and search capabilities Front-end built with modern frameworks (React or Vue.js) using AWS Amplify This architecture enables a generative AI-powered chatbot solution that can scale with demand while providing intelligent responses based on both LLMs\u0026rsquo; knowledge and enterprise-specific knowledge. The use of React or Vue.js with AWS Amplify ensures a responsive and efficient user interface.\nAmazon Kendra Amazon Kendra is a managed information retrieval and intelligent search service that uses natural language processing and advanced deep learning model. Unlike traditional keyword-based search, Amazon Kendra uses semantic and contextual similarity‚Äîand ranking capabilities‚Äîto decide whether a text chunk or document is relevant to a retrieval query.\nSource: Amazon Kendra ‚Äì What is Kendra?\nThis source provides a more detailed explanation of how Amazon Kendra works.\nAmazon Bedrock Amazon Bedrock is a fully managed service that makes high-performing foundation models (FMs) from leading AI companies and Amazon available for your use through a unified API. You can choose from a wide range of foundation models to find the model that is best suited for your use case. Amazon Bedrock also offers a broad set of capabilities to build generative AI applications with security, privacy, and responsible AI. Using Amazon Bedrock, you can easily experiment with and evaluate top foundation models for your use cases, privately customize them with your data using techniques such as fine-tuning and Retrieval Augmented Generation (RAG), and build agents that execute tasks using your enterprise systems and data sources.\nWith Amazon Bedrock\u0026rsquo;s serverless experience, you can get started quickly, privately customize foundation models with your own data, and easily and securely integrate and deploy them into your applications using AWS tools without having to manage any infrastructure.\nSource: Amazon Bedrock ‚Äì What is Amazon Bedrock?\nThis source provides a more detailed explanation of how Amazon Bedrock works.\n"
},
{
	"uri": "//localhost:1313/2-prerequiste/2.1-launchastack/",
	"title": "Launch a CloudFormation stack",
	"tags": [],
	"description": "",
	"content": "\rSupported Regions: We recommended that you run this workshop in the us-west-2 AWS Region.\nAn AWS CloudFormation template is used to set up lab resources in the AWS Region that you choose. This step is required because later instructions are based on these resources. The CloudFormation template creates the following AWS resources:\nVSCode: VSCode on Amazon EC2 is a cloud-based integrated development environment (IDE) that you can use to write, run, and debug your code with just a browser. It includes a code editor, debugger, and terminal. In this workshop, you use VSCode editor to deploy a backend application, which is built by using AWS Serverless Application Model (AWS SAM), and also deploy AWS Amplify frontend. Amazon S3: Amazon Simple Storage Service (Amazon S3) is an object storage service offering industry-leading scalability, data availability, security, and performance. Customers of all sizes and industries can store and protect any amount of data for virtually any use case, such as data lakes, cloud-centered applications, and mobile apps. In this workshop, you use an S3 bucket to upload your use case-centric documents. Amazon Kendra indexes these documents to provide Retrieval-Augmented Generation (RAG) answers to questions that you ask. Amazon Kendra: Amazon Kendra is an intelligent enterprise search service that helps you search across different content repositories with built-in connectors. Download the CloudFormation template: Download the CloudFormation template: Download Store the YAML template file in a folder on your local machine. Navigate to AWS CloudFormation Console üîó On the CloudFormation console, choose Upload a template file. Select the template that you just downloaded, and then choose Next Give the stack a name, such as chatbot-startup-stack\nKeep other values unchanged, and choose Next\nFor Configure stack options, select I acknowledge\u0026hellip; options and choose Next\nTo deploy the template, choose Submit After the template is deployed, to review the created resources, navigate to CloudFormation Resources, and then select the CloudFormation stack that you created.\n‚è≥ Template deployment takes 10‚Äì15 minutes to complete all AWS resource provisioning.\nCongratulations! You can now proceed to the next task.\n"
},
{
	"uri": "//localhost:1313/2-prerequiste/2.2-launchvscode/",
	"title": "Launch VSCode on AWS, and Set Up the Environment",
	"tags": [],
	"description": "",
	"content": "Launch VSCode on AWS To set up your environment, open the VSCode environment (a replacement for AWS Cloud9) which is hosted on Amazon EC2.\nOpen AWS CloudFormation console. Open chatbot-startup-stack stack. Open Outputs, Copy VSCodeWorkspaceURL and VSCodeWorkspacePassword password in a notepad. 4. Open a new browser window or tab, enter the VSCode workspace url, and enter password to launch the VSCode editor.\nAfter it is successfully launched, the default theme is white, optionally you can change to different color themes. For example, Settings Icon -\u0026gt; Themes -\u0026gt; Color Theme -\u0026gt; Dark (Visual Studio)\nYour VSCode editor is ready. Congratulations! You can now proceed to next task.\n"
},
{
	"uri": "//localhost:1313/2-prerequiste/",
	"title": "Preparation ",
	"tags": [],
	"description": "",
	"content": "\rIt is recommended to use an IAM user account with administrative privileges rather than the root account. Some AWS services, such as Knowledge Bases in Amazon Bedrock or other AI-related services, may be restricted or unavailable when using the root account. For security and compatibility reasons, AWS best practices also advise avoiding the use of the root user for daily tasks.\nSupported Regions: We recommended that you run this workshop in the us-west-2 AWS Region.\nIn this workshop, you configure the following AWS services to build a generative AI chatbot.\nAmazon Bedrock Knowledge Bases Amazon Kendra AWS Lambda An AWS CloudFormation template is used to set up lab resources in the AWS Region that you choose. This step is required because later instructions are based on these resources\nCost: Be aware that if you run this workshop in your own AWS account, you will incur costs for resource usage. The Clean Up section in the left navigation pane can help you remove resources from your environment when you are done.\nContent 2.1 Launch a CloudFormation stack 2.2 Launch VSCode on AWS, and Set Up the Environment "
},
{
	"uri": "//localhost:1313/3-accessibilitytoinstances/",
	"title": "Deploy Amazon Bedrock Serverless Application",
	"tags": [],
	"description": "",
	"content": "In this task, you will build and deploy both the backend and frontend components of the application. The backend is deployed as a serverless application using AWS SAM, which creates an Amazon API Gateway, the necessary AWS Lambda functions, a Cognito user pool, and stores login credentials in AWS Secrets Manager.\nThe frontend is built using Vue.js and deployed using AWS Amplify. The frontend UI will call REST-based API calls hosted using Amazon API Gateway, API Gateway invokes AWS Lambda function, function calls Amazon Bedrock APIs. This serverless architecture allows the application to scale efficiently and reduces the operational overhead of managing the underlying infrastructure. The deployment process is automated through a startup.sh script, which handles the end-to-end provisioning of the entire application stack.\nBuild and deploy the chatbot application From the VSCode editor, run the following command to set a key environment variable used throughout the workshop. Replace \u0026lt;chatbot-startup-stack\u0026gt; with the actual stack name from the AWS CloudFormation console.\nThis CFNStackName variable will be referenced later when interacting with the resources provisioned as part of app deployment. And, the environment variable S3BucketName will be used throughout the workshop to store various data sources and knowledge bases required for the application. The backend services will interact with the contents of this S3 bucket to retrieve and process the necessary information for the application\u0026rsquo;s functionality. Ensuring the S3BucketName environment variable is properly set will allow the workshop tasks to seamlessly access and utilize the required data stored in this central location.\nexport CFNStackName=\u0026#34;chatbot-startup-stack\u0026#34; export S3BucketName=$(aws cloudformation describe-stacks --stack-name ${CFNStackName} --query \u0026#34;Stacks[0].Outputs[?OutputKey==\u0026#39;S3BucketName\u0026#39;].OutputValue\u0026#34; --output text) echo \u0026#34;S3 bucket name: $S3BucketName\u0026#34; To clone the source code for this workshop, run the following command. The application code is hosted in the open-source aws-samples GitHub repository, which contains a variety of sample projects provided by AWS. Cloning the repository will ensure you have the latest version of the code and can easily make any modifications as you progress through the workshop tasks.\ncd ~/environment git clone https://github.com/aws-samples/bedrock-serverless-workshop.git To build and deploy backend and frontend of serverless app, run the following command. The aws-creds.py script is used to create an AWS profile, which is a required step for the subsequent frontend deployment process..\ncd ~/environment/bedrock-serverless-workshop python3 aws-creds.py chmod +x startup.sh ./startup.sh The script is doing following tasks:\nUpgrade OS, install jq software. Build backend using sam build. Deploy backend using sam deploy. Install Amplify and build frontend. Publish the frontend application using Amplify. The script will take anywhere from 2 to 5 minutes to finish. If there is a git alert popup window at some point, choose OK.\nDuring amplify add host, you are prompted with a selection twice, keep the default selections and hit enter. The defaults are, Hosting with Amplify Console (Managed hosting with custom domains, Continuous deployment) for the first option, and Manual deployment for the second option.\nAfter completion, you will see the following image.\nCopy and store the value for amplifyapp url, user_id, and password in a text editor. You use these credentials to sign in to the UI.\nLaunch the amplifyapp url from the web browser, login using above credentials. After a successful login you see the the below home screen. Note, it is not yet ready with source documents, and the chat is not yet functional. In the next task you complete indexing your source documents and test with sample questions. Before you move to next task, run below commands, these are the environment variables required for SAM and Amplify build commands for rest of the lab.\nRun the following commands in the VS Code terminal.\nexport SAMStackName=\u0026#34;sam-$CFNStackName\u0026#34; export AWS_REGION=$(aws configure get region) export KendraIndexID=$(aws cloudformation describe-stacks --stack-name ${CFNStackName} --query \u0026#34;Stacks[0].Outputs[?OutputKey==\u0026#39;KendraIndexID\u0026#39;].OutputValue\u0026#34; --output text) export BedrockApiUrl=$(aws cloudformation describe-stacks --stack-name ${SAMStackName} --query \u0026#34;Stacks[0].Outputs[?OutputKey==\u0026#39;BedrockApiUrl\u0026#39;].OutputValue\u0026#34; --output text) export SecretName=$(aws cloudformation describe-stacks --stack-name ${SAMStackName} --query \u0026#34;Stacks[0].Outputs[?OutputKey==\u0026#39;SecretsName\u0026#39;].OutputValue\u0026#34; --output text) export BedrockApiUrl=$(aws cloudformation describe-stacks --stack-name ${SAMStackName} --query \u0026#34;Stacks[0].Outputs[?OutputKey==\u0026#39;BedrockApiUrl\u0026#39;].OutputValue\u0026#34; --output text) export UserPoolId=$(aws cloudformation describe-stacks --stack-name ${SAMStackName} --query \u0026#34;Stacks[0].Outputs[?OutputKey==\u0026#39;CognitoUserPool\u0026#39;].OutputValue\u0026#34; --output text) export UserPoolClientId=$(aws cloudformation describe-stacks --stack-name ${SAMStackName} --query \u0026#34;Stacks[0].Outputs[?OutputKey==\u0026#39;CongnitoUserPoolClientID\u0026#39;].OutputValue\u0026#34; --output text) export SecretName=$(aws cloudformation describe-stacks --stack-name ${SAMStackName} --query \u0026#34;Stacks[0].Outputs[?OutputKey==\u0026#39;SecretsName\u0026#39;].OutputValue\u0026#34; --output text) export PATH=~/.npm-global/bin:$PATH After running, you can check again by using the export command and verifying whether the above variables(AWS_REGION, KendraIndexID, BedrockApiUrl,\u0026hellip;) have been assigned values. If the variables do not have values, check your region to ensure it is set to the us-west-2 AWS Region. If it\u0026rsquo;s incorrect, delete the stack, select the correct region, and run the steps again.\nYou have completed the deployment of the backend and frontend of the chatbot using Amazon Bedrock serverless\n"
},
{
	"uri": "//localhost:1313/4-walkthroughbedrock/",
	"title": "Walkthrough Amazon Bedrock Console",
	"tags": [],
	"description": "",
	"content": "Use Amazon Bedrock to build and scale generative AI applications with FMs. Amazon Bedrock is a fully managed service that makes FMs, from leading AI startups and Amazon, available through an API. You can choose from a wide range of FMs to find the model that is best suited for your use case. With the Amazon Bedrock serverless experience, you can get started quickly, privately customize FMs with your own data, and quickly integrate and deploy them into your applications by using AWS tools without having to manage any infrastructure.\nOpen Amazon Bedrock console Activate model access To complete this workshop, you need to enable access to Claude3, Mistral, and Llama models. Additionally, verify that the Titan Text Embeddings V2 model is enabled; this model is typically available by default, but confirm its status and enable it if necessary. Please ensure you have access to all these required models before proceeding with the workshop.\nAt the upper-left of the Amazon Bedrock console, choose the menu (hamburger) icon. In the navigation pane, choose Model access, and then select Enable specific models. Select the following LLMs: Titan Text Embeddings V2 Claude 3.5 Sonnet Claude 3 Haiku Claude 3 Opus Llama 3.1 8B Instruct 8B Mistral 7B Instruct Choose Next Choose Submit In the current version of this workshop environment, the use of the Claude 3 Opus model is not supported. If you encounter any errors related to Opus, you can safely ignore them and proceed without testing the Opus model. However, if you choose to deploy this application in your own AWS account, you will be able to enable the Opus model without any issues.\nAsk a question At the upper-left of the Amazon Bedrock console, choose the menu (hamburger) icon.\nUnder Test, choose Chat / Text playground.\nYou can also take this time, on the left menu, to navigate around the different options.\nOn the Chat / Text playground, choose Select model.\nIn the Select model popup, choose Anthropic and select Claude 3 Haiku.\nChoose Apply.\nIn the prompt text box, type question, and then choose Run.\nSample question ‚Äì List top 10 cities of VietNam by population?\nThe model returns a response similar to this:\nIn the Configurations, You can try randomness by changing parameter like temperature, Top P, Top K, and token length. You can also try with a different questions and experience with different response behavior.\nTemperature is a parameter that controls the level of randomness in the output; the higher the value, the more creative the model becomes. Top P is the cumulative probability threshold for selecting candidate tokens, helping balance between logic and diversity. Top K is the number of highest-probability tokens considered for the next word selection. Max token length is the maximum number of tokens the model will generate in a response to control the output length and cost. üéâ Congratulations You can now proceed to the next task.\n"
},
{
	"uri": "//localhost:1313/5-portfwd/",
	"title": "Port Forwarding",
	"tags": [],
	"description": "",
	"content": "\rPort Forwarding is a useful way to redirect network traffic from one IP address - Port to another IP address - Port. With Port Forwarding we can access an EC2 instance located in the private subnet from our workstation.\nWe will configure Port Forwarding for the RDP connection between our machine and Private Windows Instance located in the private subnet we created for this exercise.\nCreate IAM user with permission to connect SSM Go to IAM service management console Click Users , then click Add users. At the Add user page. In the User name field, enter Portfwd. Click on Access key - Programmatic access. Click Next: Permissions. Click Attach existing policies directly.\nIn the search box, enter ssm. Click on AmazonSSMFullAccess. Click Next: Tags, click Next: Reviews. Click Create user. Save Access key ID and Secret access key information to perform AWS CLI configuration.\nInstall and Configure AWS CLI and Session Manager Plugin To perform this hands-on, make sure your workstation has AWS CLI and Session Manager Plugin installed -manager-working-with-install-plugin.html)\nMore hands-on tutorials on installing and configuring the AWS CLI can be found here.\nWith Windows, when extracting the Session Manager Plugin installation folder, run the install.bat file with Administrator permission to perform the installation.\nImplement Portforwarding Run the command below in Command Prompt on your machine to configure Port Forwarding. aws ssm start-session --target (your ID windows instance) --document-name AWS-StartPortForwardingSession --parameters portNumber=\u0026#34;3389\u0026#34;,localPortNumber=\u0026#34;9999\u0026#34; --region (your region) Windows Private Instance Instance ID information can be found when you view the EC2 Windows Private Instance server details.\nExample command: C:\\Windows\\system32\u0026gt;aws ssm start-session --target i-06343d7377486760c --document-name AWS-StartPortForwardingSession --parameters portNumber=\u0026#34;3389\u0026#34;,localPortNumber=\u0026#34;9999\u0026#34; --region ap-southeast-1 If your command gives an error like below: SessionManagerPlugin is not found. Please refer to SessionManager Documentation here: http://docs.aws.amazon.com/console/systems-manager/session-manager-plugin-not-found\nProve that you have not successfully installed the Session Manager Plugin. You may need to relaunch Command Prompt after installing Session Manager Plugin.\nConnect to the Private Windows Instance you created using the Remote Desktop tool on your workstation. In the Computer section: enter localhost:9999. Return to the administration interface of the System Manager - Session Manager service. Click tab Session history. We will see session logs with Document name AWS-StartPortForwardingSession. Congratulations on completing the lab on how to use Session Manager to connect and store session logs in S3 bucket. Remember to perform resource cleanup to avoid unintended costs.\n"
},
{
	"uri": "//localhost:1313/6-cleanup/",
	"title": "Clean up resources",
	"tags": [],
	"description": "",
	"content": "We will take the following steps to delete the resources we created in this exercise.\nDelete EC2 instance Go to EC2 service management console\nClick Instances. Select both Public Linux Instance and Private Windows Instance instances. Click Instance state. Click Terminate instance, then click Terminate to confirm. Go to IAM service management console\nClick Roles. In the search box, enter SSM. Click to select SSM-Role. Click Delete, then enter the role name SSM-Role and click Delete to delete the role. Click Users. Click on user Portfwd. Click Delete, then enter the user name Portfwd and click Delete to delete the user. Delete S3 bucket Access System Manager - Session Manager service management console.\nClick the Preferences tab. Click Edit. Scroll down. In the section S3 logging. Uncheck Enable to disable logging. Scroll down. Click Save. Go to S3 service management console\nClick on the S3 bucket we created for this lab. (Example: lab-fcj-bucket-0001 ) Click Empty. Enter permanently delete, then click Empty to proceed to delete the object in the bucket. Click Exit. After deleting all objects in the bucket, click Delete\nEnter the name of the S3 bucket, then click Delete bucket to proceed with deleting the S3 bucket. Delete VPC Endpoints Go to VPC service management console Click Endpoints. Select the 4 endpoints we created for the lab including SSM, SSMMESSAGES, EC2MESSAGES, S3GW. Click Actions. Click Delete VPC endpoints. In the confirm box, enter delete.\nClick Delete to proceed with deleting endpoints. Click the refresh icon, check that all endpoints have been deleted before proceeding to the next step.\nDelete VPC Go to VPC service management console\nClick Your VPCs. Click on Lab VPC. Click Actions. Click Delete VPC. In the confirm box, enter delete to confirm, click Delete to delete Lab VPC and related resources.\n"
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]